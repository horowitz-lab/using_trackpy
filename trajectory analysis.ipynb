{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trackpy as tp\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.lines as mlines\n",
    "import pickle\n",
    "import cv2\n",
    "import math\n",
    "from datetime import date\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "import scipy.optimize as sco\n",
    "import seaborn as sns\n",
    "import av\n",
    "from tqdm.notebook import tqdm\n",
    "import winsound\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9510b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder_list = True\n",
    "\n",
    "def find_analysis_folders(root_folder):\n",
    "    analysis_folders = []\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for folder in dirs:\n",
    "            if folder.lower() == \"analysis\":\n",
    "                analysis_folders.append(os.path.join(root, folder))\n",
    "    return analysis_folders\n",
    "\n",
    "\n",
    "def get_subfolders(analysis_folders):\n",
    "    subfolders = []\n",
    "    for folder in analysis_folders:\n",
    "        for subitem in os.listdir(folder):\n",
    "            subitem_path = os.path.join(folder, subitem)\n",
    "            if os.path.isdir(subitem_path):\n",
    "                subfolders.append(subitem_path)\n",
    "    return subfolders\n",
    "\n",
    "\n",
    "avi_folder = r'C:\\Users\\vhorowit\\Desktop\\BessLawrence\\Data'\n",
    "# avi_folder = r'G:\\Shared drives\\Horowitz Lab Notes\\Rebecca Dalphin and Alex Axton'\n",
    "AlexRebecca = False\n",
    "\n",
    "info_csv = r'C:\\Users\\vhorowit\\Desktop\\BessLawrence\\2023 Subdiffusion project data - Sheet1.csv'\n",
    "\n",
    "\n",
    "#r'G:\\Shared drives\\Horowitz Lab Notes\\Bess Lawrence Data'\n",
    "\n",
    "if create_folder_list:\n",
    "    analysis_folders = find_analysis_folders(r'C:\\Users\\vhorowit\\Desktop\\BessLawrence')\n",
    "    folderlist = get_subfolders(analysis_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ace8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.read_csv(info_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66786685",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_info_df = info_df[info_df['Blocking'] == \"Bess\"]\n",
    "this_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a43e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folderlist = [r'G:\\Shared drives\\Horowitz Lab Notes\\Rebecca Dalphin and Alex Axton\\Analysis\\2023-05-27',\n",
    "#             r'G:\\Shared drives\\Horowitz Lab Notes\\Rebecca Dalphin and Alex Axton\\Analysis\\2023-05-28']\n",
    "\n",
    "#savefolder = r'G:\\Shared drives\\Horowitz Lab Notes\\Rebecca Dalphin and Alex Axton\\Analysis\\viva-analysis'\n",
    "savefolder = r'C:\\Users\\vhorowit\\Desktop\\BessLawrence\\Viva-Analysis'\n",
    "saving = True\n",
    "\n",
    "subtract_drift_slow = True\n",
    "calculate_van_hove_slow = True\n",
    "\n",
    "# scaling, measured in microns per pixel\n",
    "#scaling = 330 / 1247.96 # 20x1.0, measured 2021-06-17\n",
    "#scaling = 220 / 1250.04 # 20x1.5, measured 2021-06-17\n",
    "scaling = 150 / 1127.54 # 40x1.0, measured 2021-06-16\n",
    "#scaling = 100 / 1130.61 # 40x1.5, measured 2021-06-16\n",
    "#scaling = 80 / 914.92 # 60x1.0, measured 2021-05-28\n",
    "#scaling = 60 / 1031.07 # 60x1.5, measured 2021-05-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datestring():\n",
    "    return datetime.datetime.today().strftime('%Y-%m-%d %H;%M;%S')\n",
    "\n",
    "#remove parentheses and numbers from filenames\n",
    "def remove_number_parentheses(filename):\n",
    "    return re.sub(r'\\(\\d\\)', '', filename)\n",
    "\n",
    "def savefigure(savename):\n",
    "    try:\n",
    "        plt.savefig(savename + '.svg', dpi = 600, bbox_inches='tight', transparent=True)\n",
    "    except:\n",
    "        print('Could not save svg')\n",
    "    try:\n",
    "        plt.savefig(savename + '.pdf', dpi = 600, bbox_inches='tight', transparent=True)\n",
    "           # transparent true source: https://jonathansoma.com/lede/data-studio/matplotlib/exporting-from-matplotlib-to-open-in-adobe-illustrator/\n",
    "    except:\n",
    "        print('Could not save pdf')\n",
    "    plt.savefig(savename + '.png', dpi = 600, bbox_inches='tight', transparent=True)\n",
    "    print(\"Saved:\\n\", savename + '.png')\n",
    "\n",
    "def beep():\n",
    "    try:\n",
    "        winsound.PlaySound(r'C:\\Windows\\Media\\Speech Disambiguation.wav', flags = winsound.SND_ASYNC)\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        winsound.PlaySound(\"SystemHand\", winsound.SND_ALIAS)\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        winsound.Beep(450,150)\n",
    "        return\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fc915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "filename_list = []\n",
    "\n",
    "\"\"\"\n",
    "Note about file names\n",
    "unfiltered.pkl = every particle trajectory, immediately after it was linked.\n",
    ".pkl = filtered to remove stubs\n",
    "nodrift.pkl = drift has been subtracted\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for folder in folderlist:\n",
    "    os.chdir(folder)\n",
    "    # Iterate over files in the folder\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('control_tracer.pkl'):\n",
    "            #print(os.path.join(folder,filename))\n",
    "            if os.path.isfile(filename):\n",
    "                df_list.append(pd.read_pickle(filename))\n",
    "                filename_list.append(os.path.join(folder,filename))\n",
    "            else:\n",
    "                print('is not a file. **************')\n",
    "            \n",
    "#filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_short_file(filepath):\n",
    "    match = re.search(r'Data Taken (\\d{4}-\\d{2}-\\d{2}), (.*)control_tracer.pkl', filepath)\n",
    "    if match:\n",
    "        extracted_part = match.group(2).strip()\n",
    "    else:\n",
    "        base_name = os.path.basename(filepath)  # Get the base name from the path\n",
    "        start_index = base_name.rfind(',') + 2  # Find the index of the comma and add 2 to skip the comma and space\n",
    "        extracted_part = base_name[start_index:].replace(\"control_tracer.pkl\", \"\").strip()  # Remove \"control_tracer.pkl\" and leading/trailing spaces\n",
    "    return extracted_part\n",
    "\n",
    "shortfiles = [extract_short_file(item) for item in filename_list]\n",
    "\n",
    "\n",
    "analysis_files_df = pd.DataFrame({'Analysis file': filename_list, 'control_tracer.pkl': shortfiles })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fps_from_avi(avi_file): # avi_file is a file path\n",
    "    assert(os.path.exists(avi_file))\n",
    "    try:\n",
    "        video = cv2.VideoCapture(avi_file)\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        video.release()\n",
    "        if fps == 0:\n",
    "            raise Exception(f\"fps must not be zero: {avi_file}\")\n",
    "    except:\n",
    "        print('Using backup method')\n",
    "        import av\n",
    "        container = av.open(avi_file)\n",
    "        fps = container.streams.video[0].average_rate\n",
    "        container.close()\n",
    "    return float(fps)\n",
    "\n",
    "data_files = []\n",
    "fps_list = []\n",
    "#os.chdir(r'G:\\Shared drives\\Horowitz Lab Notes\\Rebecca Dalphin and Alex Axton')\n",
    "#for filename in os.listdir(r'G:\\Shared drives\\Horowitz Lab Notes\\Rebecca Dalphin and Alex Axton'):\n",
    "for root, dirs, files in os.walk(avi_folder):\n",
    "    for filename in files:\n",
    "        full_path = os.path.join(root, filename)\n",
    "        if filename.endswith('.avi'):\n",
    "            #print(full_path)\n",
    "            fps = get_fps_from_avi(full_path)\n",
    "            data_files.append(full_path)\n",
    "            fps_list.append(fps)\n",
    "            #print(fps)\n",
    "\n",
    "datafiles_df = pd.DataFrame({\"Data file\":data_files, \"fps\": fps_list })\n",
    "\n",
    "datafiles_df['data_file name'] = datafiles_df['Data file'].apply(lambda x: x.split('\\\\')[-1])\n",
    "\n",
    "\"\"\"with pd.option_context('display.max_rows', None, \n",
    "                       'display.max_columns', None, \n",
    "                       'display.max_colwidth', None, \n",
    "                       'display.expand_frame_repr', False):\n",
    "    display(datafiles_df)\"\"\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687275bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = datafiles_df.merge(this_info_df, on='data_file name')\n",
    "combined_df = analysis_files_df.merge(combined_df, on='control_tracer.pkl')\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cf871",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datafiles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(this_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis_files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78342021",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(savefolder)\n",
    "\n",
    "start = time.time() # about 3 minutes\n",
    "\n",
    "if subtract_drift_slow:\n",
    "    from rotational_drift_subtraction import drift_subtract\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
    "    # Some day this will come back to bite me. Today is not that day.\n",
    "\n",
    "\n",
    "    df_list_nodrift = []\n",
    "    for df in tqdm(df_list):\n",
    "        _, df_nodrift = drift_subtract(tracer = df, show_plots=False )\n",
    "        df_list_nodrift.append(df_nodrift)\n",
    "\n",
    "\n",
    "    # Re-enable the warning\n",
    "    warnings.filterwarnings(\"default\", category=PendingDeprecationWarning)\n",
    "    \n",
    "    data_dict = {'filename_list': filename_list, 'df_list_nodrift':df_list_nodrift}\n",
    "    with open('drift_subtracted_trajectories_dictionary.pkl', 'wb') as file:\n",
    "        pickle.dump(data_dict, file)\n",
    "else:\n",
    "    with open('drift_subtracted_trajectories_dictionary.pkl', 'rb') as file:\n",
    "        data_dict = pickle.load(file)\n",
    "    # Extract elements from the dictionary\n",
    "    filename_list = data_dict['filename_list']\n",
    "    df_list_nodrift = data_dict['df_list_nodrift']\n",
    "    \n",
    "    \n",
    "end = time.time()\n",
    "print((end-start)/60, 'minutes elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aad380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_nodrift = pd.DataFrame(data_dict)['df_list_nodrift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "if debug and len(filename_list) == len(df_list_nodrift):\n",
    "    df_list_nodrift_orig = df_list_nodrift.copy()\n",
    "    df_list_nodrift = df_list_nodrift[10:15]\n",
    "else:\n",
    "    ## Skip the beginning of the movie: it's the most likely to have dropped frames.\n",
    "    df_list_nodrift = df_list_nodrift[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17095820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalizes histogram data so that the sum of probabilities is one.\n",
    "\n",
    "@param histdata - the starting histogram\n",
    "\n",
    "@return the normalized histogram of probabilites\n",
    "\"\"\"\n",
    "def manualnorm(histdata):\n",
    "     return (1/(histdata.sum()*binwidth))*histdata\n",
    "    \n",
    "\"\"\"\n",
    "Outputs f(x) where f is a Gaussian curve.\n",
    "\n",
    "@param x - the independent variable\n",
    "@param a [0] - Gaussian amplitude\n",
    "@param center [1] - Gaussian center\n",
    "@param sigma [2] - Gaussian standard deviation (width)\n",
    "\n",
    "@return f(x)\n",
    "\"\"\"\n",
    "def gaussian(x,a,center,sigma):\n",
    "    return a*(np.exp(-((x-center)**2)/(2*(sigma**2)))) # sigma is standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shortfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_list_nodrift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f40224",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba282e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfiles == combined_df['control_tracer.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f0197",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_van_hove_slow = True\n",
    "# It takes about two minutes to do 5 lagtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb9059",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate probability distribution function (van hove)\n",
    "\n",
    "if calculate_van_hove_slow:\n",
    "    maxlagtime = 120#40 # in number of frames  \n",
    "            # for 120, maybe vanhove_max of 7. for 40, perhaps 4.  (120 took 99 minutes.)\n",
    "    skip = int(maxlagtime/5)\n",
    "    vanhove_max_x = 7\n",
    "    binwidth = 0.04\n",
    "    figsize = [8, 8]\n",
    "    \n",
    "    show_plot = False\n",
    "\n",
    "    start_time = time.time()\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "    # initializations before for loop\n",
    "    binsequence = np.arange(-vanhove_max_x, vanhove_max_x, binwidth)\n",
    "    trackshistlistlist = []\n",
    "    trackshistlistlisty = []\n",
    "    kurtosisdflist = []\n",
    "    kurtosisdflisty = []\n",
    "    lagtimelist = []\n",
    "    color_mapping = {}\n",
    "    numplots = int(maxlagtime / skip)\n",
    "    i = 0\n",
    "    big_klist = []\n",
    "    big_xylist = []\n",
    "    big_tlist = []\n",
    "    big_filepathlist = []\n",
    "    big_descriptionlist = []\n",
    "    if show_plot:\n",
    "        fig, axs = plt.subplots(int(math.ceil(numplots / 5)), 5, figsize=figsize, dpi=300)\n",
    "        fig2, ax2 = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "\n",
    "    assert(len(shortfiles) ==len(df_series_nodrift))   \n",
    "\n",
    "    for (row_tuple, file, filepath, df, fps, ii) in tqdm(zip(combined_df.itertuples(), \n",
    "                                                             combined_df['control_tracer.pkl'], \n",
    "                                                             combined_df['Analysis file'], \n",
    "                                                             df_series_nodrift, \n",
    "                                                             combined_df.fps, \n",
    "                                                             range(len(combined_df)))):\n",
    "        if AlexRebecca:\n",
    "            this_description = re.sub(r'\\(\\d\\)$', '', file).strip()\n",
    "        else:\n",
    "            this_description = row_tuple.Description\n",
    "\n",
    "        if this_description not in color_mapping:\n",
    "            color_mapping[this_description] = plt.rcParams['axes.prop_cycle'].by_key()['color'][i % len(plt.rcParams['axes.prop_cycle'])]\n",
    "            i += 1\n",
    "\n",
    "        color = color_mapping[this_description]\n",
    "\n",
    "        tracksbyframex = df.set_index(['frame', 'particle'])['x'].unstack()\n",
    "        tracksbyframey = df.set_index(['frame', 'particle'])['y'].unstack()\n",
    "        trackshistlist = []\n",
    "        trackshistlisty = []\n",
    "        klist = []\n",
    "        kylist = []\n",
    "        tlist = []\n",
    "        \n",
    "\n",
    "        j = 0\n",
    "        for vanhove_lagtime_inframes in range(1, maxlagtime + 1, skip):\n",
    "            if ii == 0:\n",
    "                lagtimelist.append(vanhove_lagtime_inframes/fps)\n",
    "                \n",
    "            if show_plot:\n",
    "                plt.sca(axs.flat[j])\n",
    "                plt.title(\"{:.2f} ms\".format(1000 * vanhove_lagtime_inframes / fps))\n",
    "\n",
    "            # calculate vanhove / probability distribution function\n",
    "            trackshist = manualnorm(tp.motion.vanhove(\n",
    "                tracksbyframex, lagtime=vanhove_lagtime_inframes, mpp=scaling, bins=binsequence, ensemble=True))\n",
    "            trackshist.name = 'x Probability distribution'\n",
    "            trackshisty = manualnorm(tp.motion.vanhove(\n",
    "                tracksbyframey, lagtime=vanhove_lagtime_inframes, mpp=scaling, bins=binsequence, ensemble=True))\n",
    "            trackshisty.name = 'y Probability distribution'\n",
    "            if show_plot:\n",
    "                trackshist.plot(ax=axs.flat[j], label=file, color=color)\n",
    "                trackshisty.plot(ax=axs.flat[j], label=file, color=color)\n",
    "            trackshistlist.append(trackshist)\n",
    "            trackshistlisty.append(trackshisty)\n",
    "\n",
    "            kx = trackshist.kurtosis()\n",
    "            klist.append(kx)\n",
    "            ky = trackshisty.kurtosis()\n",
    "            kylist.append(ky)\n",
    "            \n",
    "            big_klist.append(kx)\n",
    "            big_xylist.append('x')\n",
    "            big_klist.append(ky)\n",
    "            big_xylist.append('y')\n",
    "            tlist.append(vanhove_lagtime_inframes / fps)\n",
    "            big_tlist.append(vanhove_lagtime_inframes / fps)\n",
    "            big_tlist.append(vanhove_lagtime_inframes / fps)\n",
    "            big_filepathlist.append(filepath)\n",
    "            big_filepathlist.append(filepath)\n",
    "            big_descriptionlist.append(this_description)\n",
    "            big_descriptionlist.append(this_description)\n",
    "            j += 1\n",
    "\n",
    "        kurtosisdf = pd.DataFrame({'time (s)': tlist, file + ' kurtosis': klist})\n",
    "        kurtosisdfy = pd.DataFrame({'time (s)': tlist, file + ' kurtosis': kylist})\n",
    "        if show_plot:\n",
    "            plt.sca(ax2)\n",
    "            plt.xlabel('lag time (s)')\n",
    "            plt.ylabel('kurtosis')\n",
    "            kurtosisdf.set_index('time (s)').plot(label=file, ax=ax2, color=color)\n",
    "\n",
    "        trackshistlistlist.append(trackshistlist)\n",
    "        trackshistlistlisty.append(trackshistlisty)\n",
    "        kurtosisdflist.append(kurtosisdf)\n",
    "        kurtosisdflisty.append(kurtosisdfy)\n",
    "\n",
    "    big_kurtosis_dict = {\n",
    "        'File': big_filepathlist,\n",
    "        'Description': big_descriptionlist,\n",
    "        'time (s)': big_tlist,\n",
    "        'kurtosis': big_klist,\n",
    "        'xy': big_xylist,\n",
    "    }\n",
    "    big_kurtosis_df = pd.DataFrame(big_kurtosis_dict, index=[big_tlist, big_filepathlist ])\n",
    "    if show_plot:\n",
    "        ax2.set_yscale('log')\n",
    "        plt.ylabel('kurtosis')\n",
    "\n",
    "        ## I want to consolidate the figure legend to just the unique filenames (not counting (1), (2), (3))\n",
    "        # Get the legend handles and labels\n",
    "        legend_handles, legend_labels = ax2.get_legend_handles_labels()\n",
    "\n",
    "        # Extract the short file names using regular expressions\n",
    "        short_labels = []\n",
    "        handle_mapping = {}\n",
    "\n",
    "        for handle, label in zip(legend_handles, legend_labels):\n",
    "            match = re.search(r'(.+?) \\(\\d+\\) kurtosis', label)\n",
    "            if match:\n",
    "                short_label = match.group(1)\n",
    "                if short_label not in handle_mapping:\n",
    "                    handle_mapping[short_label] = handle\n",
    "                    short_labels.append(short_label)\n",
    "            else:\n",
    "                short_labels.append(label)\n",
    "\n",
    "        # Create new handles using the handle mapping dictionary\n",
    "        new_handles = [handle_mapping[label] for label in short_labels]\n",
    "\n",
    "        # Set the modified handles and labels\n",
    "        ax2.legend(new_handles, short_labels, bbox_to_anchor=(1, 1), loc='upper left')  # Move the legend to the right\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    warnings.filterwarnings(\"default\", category=RuntimeWarning)\n",
    "    warnings.filterwarnings(\"default\", category=DeprecationWarning)\n",
    "\n",
    "    ## Calculate the Gaussian fitting parameters and store the information\n",
    "    do_curvefit = True\n",
    "    show_curvefit = False\n",
    "\n",
    "    gaussian_fit_paramsxlistlist = []\n",
    "    gaussian_fit_paramsylistlist = []\n",
    "    gaussian_fit_covmxlistlist = []\n",
    "    gaussian_fit_covmylistlist = []\n",
    "    \n",
    "    big_sigmalist = []\n",
    "    big_tlist = []\n",
    "    big_filepathlist = []\n",
    "    big_descriptionlist = []\n",
    "    big_sigma_stderr = []\n",
    "    big_xy_list = []\n",
    "\n",
    "    sigma_index = 2 # Index of the parameter\n",
    "    \n",
    "    if show_curvefit:\n",
    "        fig, axs = plt.subplots(int(math.ceil(numplots / 5)), 5, figsize=figsize, dpi=300)\n",
    "        fig3, axsy = plt.subplots(int(math.ceil(numplots / 5)), 5, figsize=figsize, dpi=300)\n",
    "        fig.suptitle('Probability distribution in x direction')\n",
    "        fig3.suptitle('Probability distribution in y direction')\n",
    "\n",
    "    if do_curvefit:\n",
    "        for filename, file, trackshistlist, trackshistlisty, kurtosisdf, kurtosisdfy in tqdm(zip(\n",
    "            filename_list, shortfiles, trackshistlistlist, trackshistlistlisty, kurtosisdflist, kurtosisdflisty\n",
    "        )):\n",
    "            gaussian_fit_paramsxlist = []\n",
    "            gaussian_fit_paramsylist = []\n",
    "            gaussian_fit_covmxlist = []\n",
    "            gaussian_fit_covmylist = []\n",
    "\n",
    "            j = 0\n",
    "            for vanhove_lagtime_insecs, trackshist, trackshisty in zip(\n",
    "                lagtimelist, trackshistlist, trackshistlisty\n",
    "            ):\n",
    "\n",
    "                gaussian_fit_paramsx, gaussian_fit_covmx = sco.curve_fit(gaussian, trackshist.index, trackshist.values)\n",
    "                gaussian_fit_paramsy, gaussian_fit_covmy = sco.curve_fit(gaussian, trackshisty.index, trackshisty.values)\n",
    "\n",
    "                sigma_x_stderr = np.sqrt(gaussian_fit_covmx[sigma_index, sigma_index])\n",
    "                sigma_y_stderr = np.sqrt(gaussian_fit_covmy[sigma_index, sigma_index])\n",
    "\n",
    "                \n",
    "                for p in range(2):\n",
    "                    big_filepathlist.append(filename)\n",
    "                    big_descriptionlist.append(remove_number_parentheses(file))\n",
    "                    big_tlist.append(vanhove_lagtime_insecs)\n",
    "\n",
    "                big_xy_list.append('x')\n",
    "                big_sigmalist.append(gaussian_fit_paramsx[sigma_index])\n",
    "                big_sigma_stderr.append(sigma_x_stderr)\n",
    "                \n",
    "                big_xy_list.append('y')\n",
    "                big_sigmalist.append(gaussian_fit_paramsy[sigma_index])\n",
    "                big_sigma_stderr.append(sigma_y_stderr)\n",
    "                \n",
    "                if show_curvefit:\n",
    "                    # Vary colors if this_description is different\n",
    "                    this_description = re.sub(r\"\\(\\d\\)$\", \"\", file).strip()\n",
    "                    if this_description not in color_mapping:\n",
    "                        color_mapping[this_description] = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][\n",
    "                            i % len(plt.rcParams[\"axes.prop_cycle\"])\n",
    "                        ]\n",
    "                        i += 1\n",
    "                    color = color_mapping[this_description]\n",
    "\n",
    "                    gaussian_fitx = gaussian(trackshist.index, gaussian_fit_paramsx[0],\n",
    "                                             gaussian_fit_paramsx[1], gaussian_fit_paramsx[2])\n",
    "                    gaussian_fity = gaussian(trackshisty.index, gaussian_fit_paramsy[0],\n",
    "                                             gaussian_fit_paramsy[1], gaussian_fit_paramsy[2])\n",
    "                    (axs.flat[j]).plot(trackshist.index, gaussian_fitx, color=color, linewidth=0.3, alpha=0.3)\n",
    "                    (axsy.flat[j]).plot(trackshisty.index, gaussian_fity, color=color, linewidth=0.3, alpha=0.3)\n",
    "\n",
    "                    # Plot vanhove datapoints \n",
    "                    trackshist.plot(\n",
    "                        marker=\".\",\n",
    "                        markersize=1,\n",
    "                        linestyle=\"\",\n",
    "                        ax=axs.flat[j],\n",
    "                        label=file + \" x\",\n",
    "                        color=color,\n",
    "                        alpha=0.3,\n",
    "                    )\n",
    "\n",
    "                    trackshisty.plot(\n",
    "                        marker=\".\",\n",
    "                        markersize=1,\n",
    "                        linestyle=\"\",\n",
    "                        ax=axsy.flat[j],\n",
    "                        label=file + \" y\",\n",
    "                        color=color,\n",
    "                        alpha=0.3,\n",
    "                    )\n",
    "\n",
    "                    for ax in [axs.flat[j], axsy.flat[j]]:\n",
    "                        ax.set_title(\"{:.2f} ms\".format(1000 * vanhove_lagtime_insecs))\n",
    "                        ax.set_xticks([int(trackshist.index.min())+1, 0, int(trackshist.index.max())])\n",
    "                        ax.set_yscale(\"log\")\n",
    "                    try:\n",
    "                        (axs.flat[j]).set_xlim(xlimx[j])\n",
    "                        (axs.flat[j]).set_ylim(ylimx[j])\n",
    "                        (axsy.flat[j]).set_xlim(xlimy[j])\n",
    "                        (axsy.flat[j]).set_ylim(ylimy[j])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                gaussian_fit_paramsxlist.append(gaussian_fit_paramsx)\n",
    "                gaussian_fit_paramsylist.append(gaussian_fit_paramsy)\n",
    "                gaussian_fit_covmxlist.append(gaussian_fit_covmx)\n",
    "                gaussian_fit_covmylist.append(gaussian_fit_covmy)\n",
    "\n",
    "                j += 1\n",
    "                \n",
    "\n",
    "            # Store the lists for each file and lag time\n",
    "            gaussian_fit_paramsxlistlist.append(gaussian_fit_paramsxlist)\n",
    "            gaussian_fit_paramsylistlist.append(gaussian_fit_paramsylist)\n",
    "            gaussian_fit_covmxlistlist.append(gaussian_fit_covmxlist)\n",
    "            gaussian_fit_covmylistlist.append(gaussian_fit_covmylist)\n",
    "    \n",
    "            \n",
    "        if show_curvefit:\n",
    "            fig.tight_layout()\n",
    "            fig3.tight_layout()\n",
    "    \n",
    "    \n",
    "    big_g_dict = {\n",
    "        'File': big_filepathlist,\n",
    "        'Description': big_descriptionlist,\n",
    "        'time (s)': big_tlist,\n",
    "        #'color': color,\n",
    "        'width sigma': big_sigmalist,\n",
    "        'sigma stderr': big_sigma_stderr,\n",
    "        'xy': big_xy_list\n",
    "    }\n",
    "\n",
    "    big_gaussian_df = pd.DataFrame(big_g_dict, index=[big_tlist, big_filepathlist ])\n",
    "    big_data_df = pd.concat([big_kurtosis_df, big_gaussian_df], axis = 1)\n",
    "    \n",
    "    # Get a boolean mask of duplicated columns\n",
    "    duplicate_mask = big_data_df.columns.duplicated()\n",
    "    # Get the column indexes to keep (excluding duplicates)\n",
    "    column_indexes_to_keep = [i for i in range(len(big_data_df.columns)) if not duplicate_mask[i]]\n",
    "    # Create a new DataFrame with the selected columns (excluding duplicates)\n",
    "    big_data_df = big_data_df.iloc[:, column_indexes_to_keep]\n",
    "    \n",
    "    ## Saving results\n",
    "    # Create a dictionary to save\n",
    "    data_dict_vanhove = {\n",
    "        'filename_list': filename_list,\n",
    "        'binsequence': binsequence,\n",
    "        'trackshistlistlist': trackshistlistlist,\n",
    "        'trackshistlistlisty': trackshistlistlisty,\n",
    "        'kurtosisdflist': kurtosisdflist,\n",
    "        'kurtosisdflisty': kurtosisdflisty,\n",
    "        'gaussian_fit_paramsxlistlist': gaussian_fit_paramsxlistlist,\n",
    "        'gaussian_fit_paramsylistlist': gaussian_fit_paramsylistlist,\n",
    "        'gaussian_fit_covmxlistlist': gaussian_fit_covmxlistlist,\n",
    "        'gaussian_fit_covmylistlist': gaussian_fit_covmylistlist,\n",
    "        'lagtimelist': lagtimelist,\n",
    "        'maxlagtime': maxlagtime,\n",
    "        'skip': skip,\n",
    "        'scaling': scaling,\n",
    "        'fps': fps,\n",
    "        'big_data_df': big_data_df, # added 2023-06-22\n",
    "    }\n",
    "\n",
    "    today = date.today().isoformat() # Get today's date in ISO format\n",
    "    pickle_file = f'data_dict_vanhove_{today}_{len(lagtimelist)}lagtimes.pkl' # Create the pickle file name\n",
    "\n",
    "    os.chdir(savefolder)\n",
    "    # Save the dictionary to a pickle file\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(data_dict_vanhove, f)\n",
    "        \n",
    "    beep()\n",
    "\n",
    "    #calculate_van_hove_slow = False\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time_minutes = (end_time - start_time) / 60\n",
    "    print(\"Execution time:\", execution_time_minutes, \"minutes\")\n",
    "else: # open saved file\n",
    "    root = tk.Tk() # Create a Tkinter root window\n",
    "    root.lift()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    \n",
    "    print('Look for the file dialogue window!')\n",
    "    beep()\n",
    "    beep()\n",
    "\n",
    "    # Open the file dialog to select the pickle file\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Pickle Files\", \"*.pkl\")])\n",
    "\n",
    "    # Check if a file was selected\n",
    "    if file_path:\n",
    "        # Process the selected pickle file\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data_dict_vanhove = pickle.load(f)\n",
    "        # Extract the variables from the dictionary\n",
    "        filename_list = data_dict_vanhove['filename_list']\n",
    "        binsequence = data_dict_vanhove['binsequence']\n",
    "        trackshistlistlist = data_dict_vanhove['trackshistlistlist']\n",
    "        trackshistlistlisty = data_dict_vanhove['trackshistlistlisty']\n",
    "        kurtosisdflist = data_dict_vanhove['kurtosisdflist']\n",
    "        kurtosisdflisty = data_dict_vanhove['kurtosisdflisty']\n",
    "        gaussian_fit_paramsxlistlist = data_dict_vanhove['gaussian_fit_paramsxlistlist']\n",
    "        gaussian_fit_paramsylistlist = data_dict_vanhove['gaussian_fit_paramsylistlist']\n",
    "        gaussian_fit_covmxlistlist = data_dict_vanhove['gaussian_fit_covmxlistlist']\n",
    "        gaussian_fit_covmylistlist = data_dict_vanhove['gaussian_fit_covmylistlist']\n",
    "        lagtimelist = data_dict_vanhove['lagtimelist']  # in seconds\n",
    "        maxlagtime = data_dict_vanhove['maxlagtime']  # in number of frames\n",
    "        skip = data_dict_vanhove['skip']  # in number of frames\n",
    "        scaling = data_dict_vanhove['scaling']  # in microns per pixel\n",
    "        fps = data_dict_vanhove['fps']  # in Hz\n",
    "        try:\n",
    "            big_data_df = data_dict_vanhove['big_data_df']\n",
    "            \n",
    "            ## If big_data_df has duplicated columns, this will remove them.\n",
    "            # Get a boolean mask of duplicated columns\n",
    "            duplicate_mask = big_data_df.columns.duplicated()\n",
    "            # Get the column indexes to keep (excluding duplicates)\n",
    "            column_indexes_to_keep = [i for i in range(len(big_data_df.columns)) if not duplicate_mask[i]]\n",
    "            # Create a new DataFrame with the selected columns\n",
    "            big_data_df = big_data_df.iloc[:, column_indexes_to_keep]\n",
    "        except:\n",
    "            print('Could not extract big_data_df; this must be an older file.')\n",
    "        print('Loaded file', file_path)\n",
    "    else:\n",
    "        print(\"No file selected.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_gaussian_df.index.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_kurtosis_df.index.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_gaussian_df.index == big_kurtosis_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.multi_sparse', False):\n",
    "    display(list(big_gaussian_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55321d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_kurtosis_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the desired time index for plotting\n",
    "time_index = 2  # Replace with the appropriate index\n",
    "\n",
    "# Get the time value corresponding to the chosen time index\n",
    "time_value = lagtimelist[time_index] \n",
    "\n",
    "data = big_data_df[big_data_df['time (s)'] == time_value]\n",
    "\n",
    "# Create a violin plot\n",
    "sns.violinplot(x='Description', y='width sigma', data=data, color='skyblue')\n",
    "sns.stripplot(x='Description', y='width sigma', data=data, color='black', jitter=True, size=5)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Sigma')\n",
    "plt.title('Gaussian Sigma at Time ' + str(time_value) + ' s')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ffec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for Gaussian widths\n",
    "gaussian_widths = []\n",
    "gaussian_widthsx = []\n",
    "gaussian_widthsy = []\n",
    "\n",
    "for file, gaussian_fit_paramsxlist, gaussian_fit_paramsylist in zip(shortfiles, gaussian_fit_paramsxlistlist, gaussian_fit_paramsylistlist):\n",
    "    # Calculate the standard deviation (sigma) for each lag time\n",
    "    sigmas = []\n",
    "    sigmas_x = []\n",
    "    sigmas_y = []\n",
    "    for gaussian_fit_paramsx, gaussian_fit_paramsy in zip(gaussian_fit_paramsxlist, gaussian_fit_paramsylist):\n",
    "        sigma_x = gaussian_fit_paramsx[2]\n",
    "        sigma_y = gaussian_fit_paramsy[2]\n",
    "        sigmas.append((sigma_x, sigma_y))\n",
    "        sigmas_x.append(sigma_x)\n",
    "        sigmas_y.append(sigma_y)\n",
    "    gaussian_widths.append((file, sigmas))\n",
    "    gaussian_widthsx.append((file, sigmas_x))\n",
    "    gaussian_widthsy.append((file, sigmas_y))\n",
    "\n",
    "# Select the desired time index for plotting\n",
    "time_index = 1  # Replace with the appropriate index\n",
    "\n",
    "# Extract the sigma values at the chosen time index\n",
    "sigma_values_x = [width_tuple[1][time_index][0] for width_tuple in gaussian_widths]\n",
    "sigma_values_y = [width_tuple[1][time_index][1] for width_tuple in gaussian_widths]\n",
    "\n",
    "shorterfiles = [remove_number_parentheses(file) for file in shortfiles]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "sigmadf = pd.DataFrame({'Short Names': shorterfiles, 'Sigma_X': sigma_values_x, 'Sigma_Y': sigma_values_y})\n",
    "\n",
    "# Get the time value corresponding to the chosen time index\n",
    "time_value = lagtimelist[time_index] \n",
    "\n",
    "# Create a violin plot\n",
    "sns.violinplot(x='Short Names', y='Sigma_X', data=sigmadf, color='skyblue')\n",
    "sns.stripplot(x='Short Names', y='Sigma_X', data=sigmadf, color='black', jitter=True, size=5)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Sigma X')\n",
    "plt.title('Gaussian Sigma X at Time ' + str(time_value) + ' s')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Create a separate violin plot for Sigma Y\n",
    "sns.violinplot(x='Short Names', y='Sigma_Y', data=sigmadf, color='skyblue')\n",
    "sns.stripplot(x='Short Names', y='Sigma_Y', data=sigmadf, color='black', jitter=False, size=5)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Sigma Y')\n",
    "plt.title('Gaussian Sigma Y at Time ' + str(time_value) + ' s')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Sigma_X and Sigma_Y values into a single column\n",
    "combined_values = pd.melt(sigmadf, id_vars='Short Names', value_vars=['Sigma_X', 'Sigma_Y'], var_name='Variable', value_name='Sigma')\n",
    "\n",
    "# Define the order for the horizontal axis (largest to smallest)\n",
    "order = combined_values.groupby('Short Names')['Sigma'].mean().sort_values(ascending=False).index\n",
    "\n",
    "# Create a violin plot for combined Sigma_X and Sigma_Y with the specified order\n",
    "sns.violinplot(x='Short Names', y='Sigma', hue='Variable', data=combined_values, palette='muted', split=True, order=order)\n",
    "sns.stripplot(x='Short Names', y='Sigma', hue='Variable', data=combined_values, order=order, palette='dark', dodge=True, jitter=True, size=5)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Sigma ($\\mu$m)')\n",
    "plt.title('Gaussian Sigma at Time ' + str(time_value) + ' s')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.legend(title='Variable')\n",
    "\n",
    "os.chdir(r'C:\\Users\\vhorowit\\Documents\\fig-expt')\n",
    "datestr = datestring()\n",
    "if saving:\n",
    "    savefigure(datestr + 'Gaussian width violin')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2dc734",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot previously calculated probability distribution function\n",
    "\n",
    "show_curvefit = True\n",
    "plots_per_row = 5\n",
    "\n",
    "assert len(filename_list) == len(trackshistlistlist)\n",
    "assert len(filename_list) == len(trackshistlistlisty)\n",
    "assert len(filename_list) == len(kurtosisdflist)\n",
    "assert len(filename_list) == len(kurtosisdflisty)\n",
    "\n",
    "numplots = int(maxlagtime / skip)\n",
    "plots_per_column = int(math.ceil(numplots / plots_per_row))\n",
    "figsize = [8, max(2, plots_per_column*1.5)]\n",
    "\n",
    "fig, axs = plt.subplots(plots_per_column, plots_per_row, figsize=figsize, dpi=300)\n",
    "plt.subplots_adjust(top=.96)\n",
    "fig3, axsy = plt.subplots(plots_per_column, plots_per_row, figsize=figsize, dpi=300)\n",
    "plt.subplots_adjust(top=.96)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)  # Adjust the spacing between subplots\n",
    "\n",
    "for i in range(plots_per_column-1):\n",
    "    for j in range(plots_per_row):\n",
    "        axs[i, j].set_xticklabels([])  # Set shared x-axis for axs\n",
    "        axs[i, j].tick_params(bottom=True, labelbottom=True)  # Customize tick labels for the last row of axs\n",
    "\n",
    "        axsy[i, j].set_xticklabels([])  # Set shared x-axis for axsy\n",
    "        axsy[i, j].tick_params(bottom=True, labelbottom=True)  # Customize tick labels for the last row of axsy\n",
    "\n",
    "fig.suptitle('Probability distribution in x direction')\n",
    "fig3.suptitle('Probability distribution in y direction')\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1, )\n",
    "fig4, ax4 = plt.subplots(1, 1, )\n",
    "\n",
    "color_mapping = {}\n",
    "if not show_curvefit:\n",
    "    xlimx = np.zeros_like(axs.flat)\n",
    "    xlimy = np.zeros_like(axs.flat)\n",
    "    ylimx = np.zeros_like(axsy.flat)\n",
    "    ylimy = np.zeros_like(axsy.flat)\n",
    "i = 0\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # Not my fault. There's some dependency.\n",
    "\n",
    "\n",
    "for file, trackshistlist, trackshistlisty, kurtosisdf, kurtosisdfy, gaussian_fit_paramsxlist, gaussian_fit_paramsylist in tqdm(\n",
    "    zip(shortfiles, trackshistlistlist, trackshistlistlisty, kurtosisdflist, kurtosisdflisty, gaussian_fit_paramsxlistlist, gaussian_fit_paramsylistlist),\n",
    "    total=len(shortfiles),\n",
    "):\n",
    "    # Vary colors if base_filename is different\n",
    "    base_filename = re.sub(r\"\\(\\d\\)$\", \"\", file).strip()\n",
    "    if base_filename not in color_mapping:\n",
    "        color_mapping[base_filename] = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][\n",
    "            i % len(plt.rcParams[\"axes.prop_cycle\"])\n",
    "        ]\n",
    "        i += 1\n",
    "    color = color_mapping[base_filename]\n",
    "\n",
    "    j = 0\n",
    "    \n",
    "    for vanhove_lagtime_insecs, trackshist, trackshisty, gaussian_fit_paramsx, gaussian_fit_paramsy in zip(\n",
    "        lagtimelist, trackshistlist, trackshistlisty, gaussian_fit_paramsxlist, gaussian_fit_paramsylist\n",
    "    ):\n",
    "        if show_curvefit:\n",
    "            try:\n",
    "                gaussian_fitx = gaussian(trackshist.index, gaussian_fit_paramsx[0],\n",
    "                                         gaussian_fit_paramsx[1], gaussian_fit_paramsx[2])\n",
    "                gaussian_fity = gaussian(trackshisty.index, gaussian_fit_paramsy[0],\n",
    "                                         gaussian_fit_paramsy[1], gaussian_fit_paramsy[2])\n",
    "\n",
    "                (axs.flat[j]).plot(trackshist.index, gaussian_fitx, color=color, linewidth=0.3, alpha=0.3)\n",
    "                (axsy.flat[j]).plot(trackshisty.index, gaussian_fity, color=color, linewidth=0.3, alpha=0.3)\n",
    "\n",
    "                try:\n",
    "                    (axs.flat[j]).set_xlim(xlimx[j])\n",
    "                    (axs.flat[j]).set_ylim(ylimx[j])\n",
    "                    (axsy.flat[j]).set_xlim(xlimy[j])\n",
    "                    (axsy.flat[j]).set_ylim(ylimy[j])\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                print('Failed to show Gaussian fits.')\n",
    "            #ax4.scatter(x=vanhove_lagtime_insecs,y=gaussian_fit_paramsx[2], color = color, alpha = 0.3)\n",
    "        \n",
    "        # Plot vanhove datapoints \n",
    "        trackshist.plot(\n",
    "            marker=\".\",\n",
    "            markersize=1,\n",
    "            linestyle=\"\",\n",
    "            ax=axs.flat[j],\n",
    "            label=file + \" x\",\n",
    "            color=color,\n",
    "            alpha=0.3,\n",
    "        )\n",
    "\n",
    "        trackshisty.plot(\n",
    "            marker=\".\",\n",
    "            markersize=1,\n",
    "            linestyle=\"\",\n",
    "            ax=axsy.flat[j],\n",
    "            label=file + \" y\",\n",
    "            color=color,\n",
    "            alpha=0.3,\n",
    "        )\n",
    "\n",
    "        for ax in [axs.flat[j], axsy.flat[j]]:\n",
    "            ax.set_title(\"{:.2f} ms\".format(1000 * vanhove_lagtime_insecs))\n",
    "            ax.set_xticks([int(trackshist.index.min())+1, 0, int(trackshist.index.max())])\n",
    "            ax.set_yscale(\"log\")\n",
    "        if not show_curvefit:\n",
    "            xlimx[j] = axs.flat[j].get_xlim()\n",
    "            ylimx[j] = axs.flat[j].get_ylim()\n",
    "            xlimy[j] = axsy.flat[j].get_xlim()\n",
    "            ylimy[j] = axsy.flat[j].get_ylim()\n",
    "        j += 1\n",
    "        \n",
    "    # Gaussian widths\n",
    "    ax4.plot(lagtimelist, np.array(gaussian_fit_paramsxlist)[:, 2], color=color, alpha = .5)\n",
    "    ax4.plot(lagtimelist, np.array(gaussian_fit_paramsylist)[:, 2], color=color, alpha = .5)\n",
    "\n",
    "    # Kurtosis\n",
    "    kurtosisdf.set_index(\"time (s)\").plot(ax=ax2, color=color, label=file + \" x\", alpha = .3)\n",
    "    kurtosisdfy.set_index(\"time (s)\").plot(ax=ax2, color=color, label=file + \" y\", alpha = .3)\n",
    "\n",
    "warnings.resetwarnings()\n",
    "\n",
    "datestr = datestring()\n",
    "\n",
    "plt.sca(ax4)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Gaussian width (um)')\n",
    "plt.sca(ax2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel(\"Kurtosis\")\n",
    "\n",
    "fig3.tight_layout()\n",
    "fig.tight_layout()\n",
    "\n",
    "# Consolidate the figure legend to just the unique filenames (not counting (1), (2), (3))\n",
    "\n",
    "handles, legend_labels = ax2.get_legend_handles_labels()\n",
    "short_labels = []\n",
    "handle_mapping = {}\n",
    "for handle, label in zip(handles, legend_labels):\n",
    "    match = re.search(r'(.+?) \\(\\d+\\) kurtosis', label)  # Extract the short file names using regular expressions\n",
    "    if match:\n",
    "        short_label = match.group(1)\n",
    "        if short_label not in handle_mapping:\n",
    "            handle_mapping[short_label] = handle\n",
    "            short_labels.append(short_label)\n",
    "    else:\n",
    "        short_labels.append(label)\n",
    "\n",
    "new_handles = [] # Create new handles\n",
    "for label in short_labels:\n",
    "    handle = handle_mapping[label]\n",
    "    # Create new Line2D objects with solid lines and no alpha\n",
    "    new_handle = mlines.Line2D([], [], color=handle.get_color(), linestyle='-', linewidth=handle.get_linewidth())\n",
    "    new_handles.append(new_handle)\n",
    "    \n",
    "# Set the modified handles and labels\n",
    "ax2.legend(handles=new_handles, labels=short_labels, bbox_to_anchor=(1, 1), loc='upper left')  # Move the legend to the right\n",
    "\n",
    "beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa01099",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving = True\n",
    "\n",
    "if saving:\n",
    "    ## Save figures\n",
    "    plt.figure(fig)\n",
    "    savefigure(datestr + 'PDx')\n",
    "    plt.figure(fig2)\n",
    "    savefigure(datestr + 'kurtosis')\n",
    "    plt.figure(fig3)\n",
    "    savefigure(datestr + 'PDy')\n",
    "    plt.figure(fig4)\n",
    "    savefigure(datestr + 'Gaussian width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71747b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row = 2  # Select the desired row\n",
    "\n",
    "shortnames = []  # List to store the modified short names\n",
    "kurtosis_values = []  # List to store the kurtosis values\n",
    "\n",
    "for kurtosisdf in kurtosisdflist + kurtosisdflisty:\n",
    "    shortname = kurtosisdf.columns[1]  # Extract the short name from the column name\n",
    "    shortname = re.sub(r'\\(\\d\\)\\s*kurtosis', '', shortname)  # Remove the \"(1) kurtosis\" or \"(2) kurtosis\" part\n",
    "    kurtosis_value = kurtosisdf.loc[row][1]  # Extract the kurtosis value from the specified row\n",
    "\n",
    "    shortnames.append(shortname)\n",
    "    kurtosis_values.append(kurtosis_value)\n",
    "\n",
    "# Create plot\n",
    "plt.scatter(shortnames, kurtosis_values)\n",
    "plt.xlabel('Short Names')\n",
    "plt.ylabel('Kurtosis')\n",
    "plt.title('Kurtosis Values at Time ' + str(kurtosisdflist[0].loc[row][0]) + ' s')  # Use the time from the first DataFrame\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6985695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the shortnames and kurtosis_values into a list of tuples\n",
    "data = list(zip(shortnames, kurtosis_values))\n",
    "\n",
    "# Sort the list of tuples based on the kurtosis values\n",
    "sorted_data = sorted(data, key=lambda x: x[1])  # Sort by the second element of each tuple\n",
    "\n",
    "# Unzip the sorted list of tuples back into separate lists\n",
    "shortnames, kurtosis_values = zip(*sorted_data)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.scatter(shortnames, kurtosis_values)\n",
    "#plt.xlabel('Short Names')\n",
    "plt.ylabel('Kurtosis')\n",
    "plt.title('Kurtosis Values at Time ' + str(kurtosisdflist[0].loc[row][0]) + ' s')  # Use the time from the first DataFrame\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n",
    "\n",
    "# Create a violin plot\n",
    "data_df = pd.DataFrame({'Short Names': shortnames, 'Kurtosis': kurtosis_values})\n",
    "\n",
    "sns.violinplot(x='Short Names', y='Kurtosis', data=data_df, color='skyblue')\n",
    "sns.stripplot(x='Short Names', y='Kurtosis', data=data_df, color='black', jitter=True, size=5)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Kurtosis')\n",
    "plt.title('Kurtosis Values at Time ' + str(kurtosisdf.loc[row][0]) + ' s')\n",
    "plt.xticks(rotation=90);\n",
    "\n",
    "os.chdir(savefolder)\n",
    "saving = False\n",
    "if saving:\n",
    "    datestr = datestring()\n",
    "    savefigure(datestr + 'kurtosis violin plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 2  # Select the desired row\n",
    "\n",
    "shortnamesx = []  # List to store the modified short names\n",
    "shortnamesy=[]\n",
    "kurtosis_xvalues = []  # List to store the kurtosis values\n",
    "kurtosis_yvalues = []  # List to store the kurtosis values\n",
    "\n",
    "for kurtosisdf in kurtosisdflist:\n",
    "    shortname = kurtosisdf.columns[1]  # Extract the short name from the column name\n",
    "    shortname = re.sub(r'\\(\\d\\)\\s*kurtosis', '', shortname)  # Remove the \"(1) kurtosis\" or \"(2) kurtosis\" part\n",
    "    kurtosis_value = kurtosisdf.loc[row][1]  # Extract the kurtosis value from the specified row\n",
    "    \n",
    "    shortnamesx.append(shortname)\n",
    "    kurtosis_xvalues.append(kurtosis_value)\n",
    "    \n",
    "for kurtosisdf in kurtosisdflisty:\n",
    "    shortname = kurtosisdf.columns[1]  # Extract the short name from the column name\n",
    "    shortname = re.sub(r'\\(\\d\\)\\s*kurtosis', '', shortname)  # Remove the \"(1) kurtosis\" or \"(2) kurtosis\" part\n",
    "    kurtosis_value = kurtosisdf.loc[row][1]  # Extract the kurtosis value from the specified row\n",
    "    \n",
    "    shortnamesy.append(shortname)\n",
    "    kurtosis_yvalues.append(kurtosis_value)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.scatter(shortnamesx, kurtosis_xvalues)\n",
    "plt.scatter(shortnamesy, kurtosis_yvalues)\n",
    "#plt.xlabel('Short Names')\n",
    "plt.ylabel('Kurtosis')\n",
    "plt.title('Kurtosis Values at Time ' + str(kurtosisdf.loc[row][0]) + ' s')\n",
    "plt.xticks(rotation=90);  # Rotate x-axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972a2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
